{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "epochs = 10\n",
    "no_cuda = False\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = glob('C:/Users/신상훈/Desktop/새 폴더/dataset/mnist_png/training/*/*.png')[:1000]\n",
    "test_paths = glob('C:/Users/신상훈/Desktop/새 폴더/dataset/mnist_png/testing/*/*.png')[:1000]\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_paths, transform=None):\n",
    "\n",
    "        self.data_paths = data_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.data_paths[idx]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        label = int(path.split('\\\\')[-2])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(train_paths, \n",
    "            transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(\n",
    "                    mean=[0.406], \n",
    "                    std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(test_paths,\n",
    "           transforms.Compose([\n",
    "               transforms.ToTensor(), \n",
    "               transforms.Normalize(\n",
    "                   mean=[0.406], \n",
    "                   std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        print(data[0].shape, data[1].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1000 (0%)]\tLoss: 0.059764\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/1000 (0%)]\tLoss: 0.066617\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/1000 (0%)]\tLoss: 0.061564\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/1000 (0%)]\tLoss: 0.061077\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/1000 (0%)]\tLoss: 0.059673\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/1000 (0%)]\tLoss: 0.067097\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/1000 (0%)]\tLoss: 0.061144\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/1000 (0%)]\tLoss: 0.062371\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/1000 (0%)]\tLoss: 0.062909\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/1000 (0%)]\tLoss: 0.064773\n",
      "\n",
      "Test set: Average loss: 0.1304, Accuracy: 980/1000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)  # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Test mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    scheduler.step(accuracy, epoch)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    if epoch ==0:\n",
    "        grid = torchvision.utils.make_grid(data)\n",
    "        writer.add_image('images',grid,epoch)\n",
    "        writer.add_graph(model,data)\n",
    "    writer.add_scalar('Loss/train/',loss,epoch)\n",
    "    writer.add_scalar('Loss/test/',test_loss ,epoch)\n",
    "    writer.add_scalar('accuracy/test/',accuracy ,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model_weight.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 5, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = torch.load('model_weight.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[-0.1424, -0.1997,  0.0005,  0.1802,  0.1808],\n",
       "                        [-0.1228, -0.0365, -0.1675, -0.1557, -0.0544],\n",
       "                        [ 0.1942, -0.0518,  0.0126,  0.1893,  0.0361],\n",
       "                        [ 0.1618,  0.1341,  0.1897,  0.0360, -0.1614],\n",
       "                        [-0.1720, -0.1022,  0.1673,  0.1169,  0.0592]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1542, -0.1484,  0.1634, -0.0202, -0.1990],\n",
       "                        [-0.0267, -0.0491,  0.0033,  0.0847,  0.0777],\n",
       "                        [-0.1548, -0.0027, -0.0984,  0.1367,  0.1003],\n",
       "                        [ 0.1088,  0.1818,  0.0993, -0.1985,  0.0516],\n",
       "                        [-0.1378,  0.0267,  0.0028,  0.1994, -0.1360]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1973, -0.0544,  0.0323,  0.1477,  0.1638],\n",
       "                        [ 0.1526,  0.0621, -0.0573, -0.0408, -0.1071],\n",
       "                        [ 0.0374, -0.1406,  0.0684,  0.1307,  0.1724],\n",
       "                        [-0.1990,  0.1629, -0.1261, -0.0153,  0.1853],\n",
       "                        [ 0.1070, -0.0644,  0.1179, -0.1939,  0.1584]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1928, -0.0114,  0.0301, -0.0497, -0.1286],\n",
       "                        [-0.0929, -0.0163, -0.1669, -0.1648,  0.0203],\n",
       "                        [-0.1330, -0.1122, -0.0052, -0.1083,  0.1842],\n",
       "                        [-0.0744, -0.1142, -0.0563, -0.1653,  0.1024],\n",
       "                        [ 0.1708, -0.1175, -0.0766,  0.1853, -0.1456]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0538, -0.1639, -0.1793, -0.0009, -0.1149],\n",
       "                        [ 0.1083, -0.0626,  0.0008, -0.1055,  0.0820],\n",
       "                        [ 0.1857, -0.0302, -0.1241, -0.1954,  0.1922],\n",
       "                        [ 0.0848,  0.0832,  0.0347,  0.1015,  0.0722],\n",
       "                        [ 0.0980,  0.1258,  0.0294,  0.1738,  0.1257]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0077, -0.0903,  0.0139,  0.1581,  0.1294],\n",
       "                        [-0.0826, -0.0427,  0.0799,  0.0777,  0.1937],\n",
       "                        [ 0.0959,  0.0629,  0.0463, -0.1865, -0.0711],\n",
       "                        [ 0.0197, -0.1406, -0.1755,  0.1371,  0.0707],\n",
       "                        [-0.1632,  0.0106,  0.1183,  0.1173,  0.1848]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0789,  0.0888, -0.1630, -0.0254, -0.1279],\n",
       "                        [-0.0379,  0.1135,  0.0988, -0.1061, -0.0506],\n",
       "                        [-0.0398, -0.0766, -0.1106,  0.1455,  0.1368],\n",
       "                        [ 0.1672, -0.1105,  0.1454, -0.0618, -0.0482],\n",
       "                        [-0.0535, -0.0101, -0.0883,  0.0266, -0.1297]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0807, -0.1696, -0.0738, -0.1399,  0.1356],\n",
       "                        [ 0.1365, -0.1601, -0.1093,  0.1805,  0.0599],\n",
       "                        [ 0.1373, -0.1532,  0.0919,  0.1301, -0.0442],\n",
       "                        [-0.0097,  0.1467,  0.0568,  0.0604,  0.0030],\n",
       "                        [-0.0845, -0.1221,  0.2016, -0.0134,  0.1797]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1652, -0.1044,  0.0125, -0.0534, -0.0057],\n",
       "                        [ 0.1334,  0.1108, -0.1148, -0.1010, -0.1438],\n",
       "                        [-0.1697,  0.1287, -0.1239,  0.0021, -0.0005],\n",
       "                        [ 0.0338, -0.0115,  0.1045,  0.0287,  0.1447],\n",
       "                        [ 0.0425, -0.0025,  0.0294,  0.1352,  0.0318]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1413, -0.0186,  0.0017,  0.1676, -0.1898],\n",
       "                        [ 0.0206,  0.1834, -0.1004, -0.0375, -0.0132],\n",
       "                        [ 0.0671,  0.0767,  0.0456,  0.0783, -0.0870],\n",
       "                        [ 0.0856, -0.0621,  0.1265, -0.0589, -0.1711],\n",
       "                        [ 0.0155,  0.1053, -0.0070,  0.0028,  0.0004]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1052,  0.0143, -0.1806, -0.1447,  0.0101],\n",
       "                        [-0.0178,  0.1896, -0.0486,  0.1517, -0.1701],\n",
       "                        [-0.1928, -0.0206, -0.1283, -0.0592,  0.0222],\n",
       "                        [-0.1763,  0.1350, -0.1230,  0.1532,  0.0662],\n",
       "                        [-0.0398, -0.1774,  0.0317, -0.1119,  0.1740]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1690, -0.0535, -0.1112, -0.1302, -0.1062],\n",
       "                        [-0.0205,  0.0129,  0.0329,  0.1005, -0.0837],\n",
       "                        [-0.1248, -0.0428,  0.1875, -0.0260, -0.1703],\n",
       "                        [ 0.1561,  0.0480,  0.0339,  0.0332,  0.1385],\n",
       "                        [-0.0923,  0.1449,  0.1917, -0.0521,  0.1262]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1100,  0.1884, -0.0450, -0.1181, -0.0743],\n",
       "                        [-0.1366,  0.0084,  0.1953,  0.1958,  0.1513],\n",
       "                        [ 0.0197,  0.0061,  0.1349,  0.1201, -0.0202],\n",
       "                        [-0.0500,  0.0809, -0.0053, -0.1405, -0.0951],\n",
       "                        [ 0.1632,  0.1681, -0.0774, -0.0437, -0.1005]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0664,  0.1808, -0.1801,  0.0934, -0.1820],\n",
       "                        [-0.0975, -0.0434,  0.0114, -0.0343, -0.0926],\n",
       "                        [-0.0924, -0.1253, -0.1425, -0.1261,  0.1920],\n",
       "                        [-0.0981, -0.1705,  0.1345,  0.0765,  0.1382],\n",
       "                        [-0.2028, -0.1945, -0.1451, -0.1069, -0.0006]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0870,  0.1179, -0.1717,  0.0799, -0.1161],\n",
       "                        [ 0.0473,  0.0647,  0.0336,  0.0714, -0.0105],\n",
       "                        [ 0.1341,  0.0444,  0.1775,  0.0440, -0.1066],\n",
       "                        [ 0.1300,  0.0129,  0.1949, -0.0218,  0.1973],\n",
       "                        [-0.1166,  0.1012, -0.1489,  0.1372,  0.0355]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1138, -0.1728, -0.1998,  0.0957, -0.0827],\n",
       "                        [ 0.0793, -0.1193, -0.0626,  0.0002,  0.1200],\n",
       "                        [ 0.1131, -0.0183, -0.0571, -0.0040,  0.1027],\n",
       "                        [-0.1691, -0.0611, -0.1929,  0.0287, -0.0240],\n",
       "                        [ 0.1141,  0.1601, -0.1712, -0.0887, -0.0325]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0036, -0.0477, -0.1277, -0.0788, -0.0060],\n",
       "                        [ 0.1592, -0.0528,  0.1305, -0.1631,  0.0082],\n",
       "                        [-0.1578, -0.1893,  0.0185, -0.0927,  0.1467],\n",
       "                        [ 0.1564, -0.2007, -0.0151, -0.0348, -0.1145],\n",
       "                        [-0.1414, -0.0862,  0.0875,  0.0473,  0.1202]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0143,  0.1024,  0.0370, -0.0460, -0.0142],\n",
       "                        [-0.1844, -0.0060, -0.0669, -0.0688, -0.0827],\n",
       "                        [-0.0448, -0.1479,  0.0122, -0.0085, -0.0542],\n",
       "                        [ 0.1745,  0.1370,  0.0595, -0.0725,  0.0256],\n",
       "                        [-0.1366,  0.1436,  0.1915, -0.0273,  0.1555]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1872, -0.0130, -0.0756,  0.0090,  0.0326],\n",
       "                        [-0.1856, -0.0131, -0.0732,  0.1330, -0.0058],\n",
       "                        [ 0.1315,  0.1778, -0.0629,  0.0432, -0.0168],\n",
       "                        [-0.0873, -0.1107,  0.0054,  0.0617, -0.0346],\n",
       "                        [ 0.0343,  0.1261,  0.0849,  0.0839,  0.0570]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1552, -0.1224, -0.1495,  0.1305, -0.1772],\n",
       "                        [-0.1504,  0.1308,  0.1172, -0.1902,  0.1149],\n",
       "                        [-0.0459,  0.0426, -0.1265, -0.0316,  0.0437],\n",
       "                        [ 0.1533,  0.1214, -0.1100, -0.1328, -0.0134],\n",
       "                        [ 0.0639,  0.1103, -0.2004, -0.0179,  0.0059]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([-0.0921,  0.1586, -0.0518, -0.1886, -0.1186,  0.0086, -0.1489,  0.0473,\n",
       "                       0.1967,  0.0087, -0.0473,  0.1891,  0.1488,  0.1356,  0.0163,  0.0093,\n",
       "                      -0.1540,  0.0235,  0.1953,  0.0119])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[-3.9749e-02,  2.4996e-02,  4.0400e-02,  3.7813e-02,  2.4084e-03],\n",
       "                        [ 9.0228e-03,  7.9096e-03, -1.8013e-02, -6.3278e-03,  3.6551e-02],\n",
       "                        [ 5.4438e-03,  4.3254e-02, -2.9014e-02, -6.0830e-03,  6.1893e-04],\n",
       "                        [-2.6278e-02,  3.5421e-02,  3.2131e-02, -2.3465e-02,  3.9722e-02],\n",
       "                        [ 4.1582e-02, -2.6395e-02, -1.4093e-03,  4.4897e-02, -2.8745e-02]],\n",
       "              \n",
       "                       [[-6.7109e-03, -3.0127e-02,  3.2683e-02,  7.5572e-03,  1.8967e-02],\n",
       "                        [ 3.2548e-02, -6.5111e-03, -4.4335e-02,  2.4280e-03, -3.2910e-03],\n",
       "                        [ 1.6662e-02,  2.1671e-02, -2.1783e-02, -1.7236e-02,  2.8336e-02],\n",
       "                        [ 1.3147e-02,  1.0902e-02,  2.0421e-02,  2.1151e-02, -3.2122e-02],\n",
       "                        [ 3.7539e-03,  4.6084e-03, -4.3106e-02,  9.6478e-03, -4.4500e-04]],\n",
       "              \n",
       "                       [[ 3.4815e-02, -4.2387e-02,  4.2367e-02, -2.1567e-02,  2.6758e-02],\n",
       "                        [ 3.3322e-02, -5.2525e-03, -2.2697e-02, -7.2867e-03, -2.7751e-02],\n",
       "                        [ 6.0958e-03,  1.9159e-02,  9.4118e-03, -2.5709e-02,  2.4351e-02],\n",
       "                        [ 4.1834e-02, -1.2962e-02,  2.3508e-02, -2.9664e-03,  1.7824e-02],\n",
       "                        [-3.1424e-02, -3.7548e-02, -9.9265e-04, -3.7608e-02,  1.5977e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0655e-02, -4.1012e-02, -9.9552e-03, -2.1085e-02,  4.0258e-05],\n",
       "                        [-3.0519e-02,  1.1850e-02, -4.1965e-02,  9.8444e-03, -1.7404e-02],\n",
       "                        [-2.6148e-02,  3.8887e-02,  5.6304e-03, -2.9195e-02, -2.5107e-02],\n",
       "                        [-1.9827e-02, -2.6018e-02,  6.1886e-03,  1.1855e-03,  3.9394e-02],\n",
       "                        [ 9.6973e-04, -2.4101e-02,  3.8500e-02,  1.1626e-02, -9.1952e-03]],\n",
       "              \n",
       "                       [[ 3.1367e-02,  3.6817e-02, -3.7486e-02, -3.6706e-02, -2.9248e-02],\n",
       "                        [-3.8226e-02, -1.3193e-02,  1.6572e-02, -4.0658e-02, -4.3656e-02],\n",
       "                        [-3.8073e-02, -2.2830e-02,  2.8498e-02,  3.9887e-02,  4.4437e-02],\n",
       "                        [ 7.2178e-04, -3.7439e-02,  4.4120e-02, -2.9772e-02,  1.6955e-02],\n",
       "                        [ 2.2213e-02,  1.3796e-02,  1.5004e-02, -4.1480e-02, -1.4887e-02]],\n",
       "              \n",
       "                       [[-2.7958e-02,  3.1344e-02, -2.4979e-02, -8.4252e-04,  3.9990e-02],\n",
       "                        [ 3.4713e-02, -3.1552e-02, -3.6738e-02,  3.5802e-02,  1.3270e-02],\n",
       "                        [-3.3835e-02,  3.9126e-02, -3.1656e-02,  3.9400e-02,  3.2717e-02],\n",
       "                        [ 3.2050e-02, -8.5879e-03,  4.3134e-03, -3.6663e-02,  2.5911e-02],\n",
       "                        [ 2.8555e-03,  3.3064e-02, -1.8903e-02,  4.3503e-02,  3.0321e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2621e-02,  1.2102e-02, -3.2663e-02, -2.9789e-02, -3.0663e-02],\n",
       "                        [-2.5884e-02,  1.2225e-02, -1.9345e-02, -1.5484e-02,  3.1233e-02],\n",
       "                        [ 7.1025e-03, -2.2083e-02, -1.2276e-02, -1.1848e-02,  2.0805e-02],\n",
       "                        [ 3.1206e-02,  3.5448e-02, -3.0496e-02, -4.8545e-03,  1.0438e-02],\n",
       "                        [-1.7603e-02,  2.9340e-02, -5.0008e-03,  4.7303e-03, -3.8261e-02]],\n",
       "              \n",
       "                       [[ 3.2180e-02, -2.9774e-02, -1.1604e-03, -3.6532e-02,  3.3948e-02],\n",
       "                        [ 2.4199e-03,  1.9914e-02, -3.5254e-02,  3.7348e-03,  1.8228e-02],\n",
       "                        [ 3.1350e-02,  3.2607e-02, -8.1043e-03, -4.6312e-03,  1.4759e-02],\n",
       "                        [-1.6309e-02, -1.8374e-02, -4.1225e-02, -4.3924e-02, -2.3628e-02],\n",
       "                        [ 5.4910e-03,  3.5260e-03,  3.5453e-03,  6.6418e-03, -8.3259e-03]],\n",
       "              \n",
       "                       [[-4.4344e-02,  3.9836e-02, -3.2745e-02, -5.4685e-04,  1.7740e-02],\n",
       "                        [ 1.1296e-02, -1.9537e-02, -3.8898e-02,  3.5775e-02,  1.2443e-03],\n",
       "                        [ 4.0560e-02,  2.0724e-02,  1.9069e-02,  9.6369e-03, -1.0125e-02],\n",
       "                        [-2.6413e-02,  5.3167e-03,  4.2928e-02,  2.6767e-02,  4.0590e-02],\n",
       "                        [ 4.1801e-02,  3.4855e-02, -2.5126e-02, -2.4374e-02, -1.5619e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.4453e-02,  3.0745e-02, -2.8781e-02, -3.4303e-02,  1.8250e-02],\n",
       "                        [-2.6382e-02,  3.2238e-02,  1.9140e-02, -2.1757e-02, -9.8613e-03],\n",
       "                        [-2.0622e-02, -4.4493e-03, -2.6239e-04, -1.1591e-03, -2.9271e-02],\n",
       "                        [-3.7378e-02, -2.8664e-02,  7.4930e-03,  4.5552e-03, -2.2543e-02],\n",
       "                        [-7.2701e-03, -1.1593e-03,  3.1941e-02, -4.0231e-02, -1.9959e-02]],\n",
       "              \n",
       "                       [[-6.4136e-03, -7.4408e-03, -2.3689e-02,  2.2239e-02, -1.6829e-02],\n",
       "                        [ 4.4881e-03, -2.5585e-02,  4.4234e-02, -2.6433e-02, -9.4136e-03],\n",
       "                        [ 3.5665e-02,  2.4130e-02, -4.0391e-02,  2.8377e-02, -2.3907e-02],\n",
       "                        [-5.6212e-03,  1.8165e-02,  2.8285e-03,  3.4380e-02, -1.6890e-02],\n",
       "                        [-3.1286e-02,  2.7873e-03,  1.5335e-02,  3.3629e-02, -2.2751e-02]],\n",
       "              \n",
       "                       [[-5.1452e-03, -2.5953e-02, -3.2621e-02, -3.5169e-02, -3.1833e-02],\n",
       "                        [-2.7132e-02,  1.4584e-02, -6.3664e-03,  2.7903e-02,  3.4095e-02],\n",
       "                        [-3.4751e-02,  8.5184e-03,  2.4224e-02, -3.6377e-02, -1.3092e-02],\n",
       "                        [ 3.2371e-02, -3.3158e-02,  3.9815e-02,  3.6788e-03,  7.9658e-03],\n",
       "                        [ 3.7223e-02, -4.1829e-02,  3.8054e-02, -4.0072e-02,  2.1076e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7326e-03,  3.5498e-02, -3.4794e-04, -4.3935e-02,  5.6828e-03],\n",
       "                        [ 3.0182e-02, -8.4105e-03, -4.2115e-02, -6.3644e-03,  3.3945e-03],\n",
       "                        [ 1.1391e-02,  1.4680e-02, -5.9052e-03, -2.4348e-03, -9.6339e-03],\n",
       "                        [ 1.7610e-02,  1.0510e-02,  1.8074e-02, -4.3201e-03, -4.4069e-03],\n",
       "                        [ 3.3183e-02,  5.7578e-03, -4.0923e-02,  8.8633e-03,  4.1299e-02]],\n",
       "              \n",
       "                       [[-8.4473e-03,  2.7208e-02, -3.2052e-02, -6.8553e-03,  2.9868e-02],\n",
       "                        [-2.2114e-02, -1.1019e-02,  4.9000e-04, -6.8025e-03, -1.2639e-02],\n",
       "                        [ 3.1195e-02, -7.7896e-03, -1.2048e-02,  3.3438e-02,  9.8154e-03],\n",
       "                        [-2.0801e-02,  2.7090e-02, -2.1989e-02,  4.4426e-02,  3.7007e-02],\n",
       "                        [ 4.4523e-03,  1.2481e-02, -1.8114e-02, -3.4663e-02, -3.1814e-02]],\n",
       "              \n",
       "                       [[ 1.4675e-02,  2.2210e-02, -4.5152e-04, -1.4669e-02, -1.4564e-02],\n",
       "                        [-2.4230e-02, -2.6659e-02,  2.9550e-02, -3.8694e-02,  3.2579e-02],\n",
       "                        [ 2.5189e-02, -1.1865e-02, -5.8010e-03, -1.5146e-02, -3.7748e-02],\n",
       "                        [ 3.9804e-03, -3.4001e-02,  1.2375e-03, -1.5753e-02, -3.4772e-02],\n",
       "                        [-4.1147e-02,  3.9947e-02,  3.4661e-02,  4.0729e-02,  1.6626e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.8041e-02, -1.2576e-02,  2.5831e-03, -5.1291e-03,  1.8215e-02],\n",
       "                        [-3.9651e-02, -2.6071e-02, -6.0122e-03, -1.4506e-03, -9.8412e-03],\n",
       "                        [ 2.0646e-02,  2.3298e-02, -7.9840e-03, -2.2577e-03, -7.1151e-03],\n",
       "                        [ 4.5509e-03, -1.8657e-02, -6.9556e-03, -3.2854e-02,  3.7384e-02],\n",
       "                        [ 3.0644e-02, -3.0395e-02,  3.2952e-03, -2.6258e-02, -8.9287e-03]],\n",
       "              \n",
       "                       [[-3.9482e-02, -2.6402e-03, -2.0127e-02, -4.0183e-02,  4.3844e-02],\n",
       "                        [ 1.1612e-02,  3.1023e-02,  7.5342e-03,  2.2880e-03, -2.0539e-02],\n",
       "                        [ 1.8097e-02,  2.8937e-02, -2.4948e-03, -2.3089e-02,  3.5660e-02],\n",
       "                        [-3.7085e-03, -2.9211e-02,  2.5492e-02,  4.3844e-02,  4.2002e-02],\n",
       "                        [ 3.6852e-02,  4.0608e-02, -4.4320e-02,  1.5236e-02,  3.8742e-02]],\n",
       "              \n",
       "                       [[-2.9032e-02,  1.1747e-02, -1.3994e-02, -3.0012e-03,  2.0846e-02],\n",
       "                        [ 3.2669e-03, -1.6128e-02, -8.2667e-03,  1.7188e-02, -2.2433e-02],\n",
       "                        [ 2.9718e-02, -4.1589e-02, -3.0406e-02,  1.2546e-02,  1.4149e-03],\n",
       "                        [ 2.5507e-02,  1.9162e-02,  2.2057e-03,  7.0292e-03,  3.2901e-02],\n",
       "                        [-4.1995e-02, -1.5309e-02,  2.8919e-02, -3.4772e-02,  2.1501e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.9493e-02, -3.9127e-02, -4.2906e-02, -3.4561e-02, -2.2835e-02],\n",
       "                        [-4.1587e-02,  1.6615e-02,  2.1856e-03, -2.7073e-02,  3.9046e-02],\n",
       "                        [-3.5402e-02,  4.1361e-02,  3.9205e-02,  2.0405e-02,  3.8386e-02],\n",
       "                        [ 1.4247e-02, -1.9016e-02,  9.7741e-03,  1.2052e-02, -3.0675e-02],\n",
       "                        [-2.5838e-03,  3.3817e-02,  4.1901e-03, -3.8132e-02,  4.7352e-03]],\n",
       "              \n",
       "                       [[-1.7691e-02, -1.4771e-02, -1.4874e-02, -3.4809e-02, -1.7774e-02],\n",
       "                        [ 3.5973e-02,  2.6514e-02,  2.9188e-02, -2.6280e-02, -2.7567e-02],\n",
       "                        [ 2.6455e-02,  1.3387e-02, -1.8343e-02,  6.8546e-03,  8.3165e-03],\n",
       "                        [ 1.5590e-03, -1.6960e-02, -3.1442e-02,  1.3604e-02,  1.0949e-03],\n",
       "                        [-1.3824e-03,  1.3228e-03,  4.8888e-03, -2.4643e-02, -1.7370e-02]],\n",
       "              \n",
       "                       [[ 2.7055e-02, -3.2195e-02, -6.7561e-03, -1.3129e-02, -6.1572e-03],\n",
       "                        [-3.9369e-02, -1.2275e-02, -2.6844e-02, -3.8118e-02,  2.8160e-02],\n",
       "                        [ 4.1820e-02,  2.9353e-02,  1.1201e-02,  1.8551e-02,  4.2573e-02],\n",
       "                        [-1.4194e-02, -2.6055e-02,  3.3317e-02,  4.0216e-02,  1.6392e-03],\n",
       "                        [-1.7489e-05, -3.1637e-03,  2.5842e-02,  2.6013e-02,  1.7464e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4463e-02, -2.5469e-02,  1.4603e-02,  4.1451e-02,  2.5804e-02],\n",
       "                        [ 1.4730e-02,  1.3740e-02,  4.2518e-02, -1.9917e-02, -1.9568e-02],\n",
       "                        [ 4.4255e-02,  1.4203e-02, -3.2747e-02, -3.2202e-02,  1.8861e-02],\n",
       "                        [-1.7710e-02,  2.3881e-02,  2.8044e-02, -3.0656e-02, -3.6405e-02],\n",
       "                        [-1.0897e-02, -2.5139e-03,  2.4559e-03, -1.5395e-02,  3.8496e-02]],\n",
       "              \n",
       "                       [[-3.0749e-02, -2.6436e-02, -9.9274e-03,  3.1799e-02,  2.1296e-02],\n",
       "                        [ 3.8318e-03,  1.0749e-02, -2.5631e-02, -1.6875e-03, -1.1148e-02],\n",
       "                        [ 4.1194e-02,  2.4307e-02, -4.2909e-03,  9.8158e-03, -1.3284e-02],\n",
       "                        [ 7.9446e-03, -2.7423e-02, -1.2657e-02,  4.0662e-02,  1.8467e-03],\n",
       "                        [-5.7552e-03, -2.7911e-02, -6.3536e-03,  2.3429e-02,  4.1466e-02]],\n",
       "              \n",
       "                       [[ 1.6435e-02,  1.1803e-02, -3.3327e-02,  3.9470e-02,  2.6282e-02],\n",
       "                        [-2.1544e-02, -1.0703e-02, -3.9945e-02,  3.5876e-02, -3.4763e-02],\n",
       "                        [-2.2341e-02,  3.0701e-02, -1.5047e-02,  1.5012e-02, -4.2034e-02],\n",
       "                        [-1.9289e-02, -4.3826e-02,  1.4805e-02, -1.4180e-02,  3.1836e-02],\n",
       "                        [ 3.6354e-02,  1.5948e-02, -1.1118e-02,  1.6135e-02,  1.2948e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0663e-02, -2.0501e-02,  1.5309e-02,  1.8002e-03, -2.1589e-02],\n",
       "                        [ 5.2123e-03, -2.6182e-02,  1.6673e-02, -2.5790e-03,  4.5568e-02],\n",
       "                        [ 2.7692e-02, -1.9661e-02, -4.1524e-03,  1.1690e-02, -1.5634e-02],\n",
       "                        [ 2.5270e-02, -2.0325e-02, -2.5881e-03,  2.5752e-02,  1.3886e-02],\n",
       "                        [ 4.0725e-02,  4.6068e-02,  7.4453e-03, -7.6534e-04, -2.9424e-02]],\n",
       "              \n",
       "                       [[-1.3935e-02,  4.3338e-02,  8.9834e-03,  1.7498e-02,  3.5998e-03],\n",
       "                        [-1.5100e-02, -2.9292e-02,  3.7448e-02, -6.0581e-03,  4.0235e-02],\n",
       "                        [-2.3665e-02, -2.6105e-02, -1.6810e-02, -1.3752e-02, -4.3336e-02],\n",
       "                        [-6.1125e-03, -3.0022e-02,  2.0333e-02, -1.1701e-02, -3.6209e-02],\n",
       "                        [ 4.6293e-02, -2.2751e-02, -1.2498e-02, -2.4042e-02,  4.2371e-02]],\n",
       "              \n",
       "                       [[ 3.0727e-02, -1.3841e-02, -3.2627e-03,  1.2251e-03,  3.2105e-02],\n",
       "                        [ 6.3456e-03,  6.3930e-03, -7.5883e-03, -2.1369e-02,  3.6394e-02],\n",
       "                        [ 2.2104e-02,  3.8837e-02, -2.1474e-02, -1.7154e-02, -1.0054e-02],\n",
       "                        [ 3.2003e-02,  5.1477e-03, -3.3754e-02, -1.5097e-02, -9.0202e-03],\n",
       "                        [ 1.0149e-02, -1.4713e-03,  3.0857e-02,  2.2720e-02,  1.9889e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.0823e-03,  8.9478e-03, -4.8521e-03,  2.6466e-03,  8.9700e-03],\n",
       "                        [-8.0442e-03, -2.8424e-02,  3.2911e-02,  4.3569e-02, -3.9894e-02],\n",
       "                        [-1.0676e-02, -2.4467e-02, -4.0122e-02, -2.8590e-02,  3.5260e-02],\n",
       "                        [ 4.3371e-02,  3.1146e-03,  1.9679e-02,  2.1574e-02,  2.3241e-02],\n",
       "                        [ 3.5100e-02,  2.3406e-03, -4.0326e-02,  4.2299e-02,  5.5699e-04]],\n",
       "              \n",
       "                       [[ 6.4263e-03,  2.5488e-02, -1.4275e-02, -2.3852e-02, -3.0245e-02],\n",
       "                        [-6.3997e-03,  2.0101e-02, -2.2566e-03,  2.3663e-02,  4.5383e-03],\n",
       "                        [ 8.4897e-03, -2.7408e-02,  4.2226e-03, -1.6449e-02,  1.6154e-02],\n",
       "                        [ 4.5023e-02, -3.3791e-02, -4.1704e-02, -3.4595e-02, -1.3647e-02],\n",
       "                        [-2.8894e-02,  7.1640e-03,  3.6510e-03, -4.4152e-03, -2.0634e-02]],\n",
       "              \n",
       "                       [[ 4.1327e-02,  1.1637e-02,  1.2767e-02,  2.3495e-02,  4.3711e-02],\n",
       "                        [-1.9047e-02,  4.0151e-02,  2.9889e-02, -8.3535e-03,  2.7800e-03],\n",
       "                        [-3.1064e-02,  2.7946e-02,  4.5012e-02,  1.6029e-02, -4.1328e-02],\n",
       "                        [-2.3522e-02,  3.1819e-02, -1.8140e-02, -3.8566e-03,  8.2611e-03],\n",
       "                        [ 4.6217e-02, -3.9233e-02, -2.5778e-02, -3.3143e-02, -1.7669e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5339e-02, -6.5673e-03, -2.4006e-02, -2.4612e-02,  2.0813e-02],\n",
       "                        [ 2.1380e-02,  4.1387e-02,  2.4692e-02, -9.4805e-03,  8.7230e-03],\n",
       "                        [-2.7480e-02, -3.9060e-02, -6.0738e-03,  9.7099e-03,  2.7421e-02],\n",
       "                        [ 3.4199e-02, -6.4111e-03, -4.3264e-02,  2.3921e-03, -4.3046e-02],\n",
       "                        [-2.8759e-02,  2.8958e-02, -3.8186e-02,  3.4517e-02,  1.6617e-02]],\n",
       "              \n",
       "                       [[ 1.8390e-02,  2.9706e-02,  8.3215e-03,  1.8636e-02, -9.6057e-03],\n",
       "                        [ 3.5466e-02,  4.5212e-02, -3.3024e-02,  3.2844e-02, -4.0847e-02],\n",
       "                        [-2.1515e-02, -1.8999e-02, -3.7042e-02,  1.4477e-02, -2.0104e-02],\n",
       "                        [-3.8464e-02,  1.0461e-02,  4.4963e-02,  4.5241e-02,  1.7361e-02],\n",
       "                        [ 2.8444e-02,  2.0384e-02,  2.3488e-02,  4.3048e-03, -1.9665e-02]],\n",
       "              \n",
       "                       [[-1.9864e-03, -1.6011e-02,  3.1928e-02, -1.0177e-02,  2.9603e-02],\n",
       "                        [ 3.6956e-02, -1.5014e-02,  2.3119e-02,  1.2398e-02, -3.7878e-02],\n",
       "                        [-2.3289e-02, -5.1407e-04,  3.0639e-02,  1.5315e-02, -1.6905e-02],\n",
       "                        [ 5.1982e-03,  3.4847e-02, -1.3715e-02, -2.7741e-02, -1.4445e-02],\n",
       "                        [ 3.4946e-02,  1.1893e-02,  1.6208e-02,  5.9508e-03,  3.6299e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0653e-02,  2.7175e-02, -4.8152e-03,  2.0697e-02,  2.8154e-03],\n",
       "                        [-1.2902e-02,  4.3971e-02, -2.5821e-02, -2.8021e-02,  2.5558e-02],\n",
       "                        [-8.2121e-03,  3.8565e-02,  1.6594e-03, -8.0766e-03, -6.7077e-03],\n",
       "                        [ 2.0255e-02, -1.8826e-02, -3.7342e-02, -2.0898e-02, -1.5856e-02],\n",
       "                        [ 4.1538e-02,  2.8709e-02, -3.0473e-02, -8.0966e-03,  5.3138e-03]],\n",
       "              \n",
       "                       [[-2.4094e-02, -3.0047e-02,  2.6736e-02,  5.6696e-03, -4.3164e-02],\n",
       "                        [ 1.9858e-02, -2.9555e-02,  3.8940e-02,  2.3751e-02, -4.4124e-02],\n",
       "                        [ 4.0499e-02,  2.6373e-02, -2.0432e-02, -5.7585e-03,  4.2469e-02],\n",
       "                        [ 3.6023e-02,  3.1044e-02,  4.4584e-02,  1.6430e-02,  8.7374e-03],\n",
       "                        [-1.1636e-02,  2.4210e-02, -1.0932e-02,  3.1579e-02,  5.2197e-04]],\n",
       "              \n",
       "                       [[-4.2134e-04,  4.5122e-02,  2.7512e-02, -2.9950e-02, -3.5979e-02],\n",
       "                        [ 7.9146e-03,  1.0523e-02,  9.5692e-05,  3.6874e-02,  1.5207e-02],\n",
       "                        [ 1.7799e-02, -3.7146e-02,  1.2478e-02, -9.7406e-03, -1.2513e-03],\n",
       "                        [ 3.7488e-02, -3.1674e-02, -3.4942e-02,  6.9336e-03,  3.5847e-02],\n",
       "                        [ 1.5144e-02, -2.1862e-02,  7.3057e-03,  1.6850e-02,  1.8426e-02]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([ 0.0242, -0.0366,  0.0433, -0.0002, -0.0070,  0.0351, -0.0389, -0.0114,\n",
       "                      -0.0421,  0.0263, -0.0322,  0.0417, -0.0131, -0.0236, -0.0365, -0.0128,\n",
       "                       0.0298, -0.0345, -0.0079, -0.0266, -0.0033, -0.0354, -0.0074,  0.0312,\n",
       "                       0.0423,  0.0075,  0.0371, -0.0246,  0.0112, -0.0407,  0.0381,  0.0100,\n",
       "                      -0.0021, -0.0114, -0.0218, -0.0269, -0.0245, -0.0150, -0.0192, -0.0430,\n",
       "                      -0.0251, -0.0017,  0.0025,  0.0146, -0.0336, -0.0342,  0.0331, -0.0394,\n",
       "                       0.0375, -0.0178])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0109,  0.0134, -0.0199,  ...,  0.0233, -0.0324,  0.0342],\n",
       "                      [-0.0134,  0.0076, -0.0067,  ...,  0.0210, -0.0291, -0.0289],\n",
       "                      [ 0.0297,  0.0081,  0.0086,  ..., -0.0059, -0.0141, -0.0041],\n",
       "                      ...,\n",
       "                      [ 0.0317,  0.0024, -0.0014,  ..., -0.0006, -0.0153,  0.0319],\n",
       "                      [ 0.0134,  0.0012,  0.0071,  ..., -0.0289, -0.0034,  0.0034],\n",
       "                      [ 0.0056, -0.0218, -0.0140,  ...,  0.0242,  0.0166, -0.0246]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0062,  0.0204, -0.0272, -0.0109, -0.0050,  0.0044, -0.0339, -0.0115,\n",
       "                       0.0083,  0.0156,  0.0039, -0.0331,  0.0223, -0.0071,  0.0146, -0.0128,\n",
       "                      -0.0123,  0.0300,  0.0289,  0.0351,  0.0349,  0.0347,  0.0064, -0.0122,\n",
       "                       0.0268, -0.0024,  0.0220,  0.0056,  0.0209,  0.0288, -0.0337,  0.0221,\n",
       "                       0.0236, -0.0148,  0.0172,  0.0360,  0.0298,  0.0275, -0.0075, -0.0346,\n",
       "                       0.0175,  0.0213, -0.0147, -0.0295,  0.0036,  0.0159, -0.0346, -0.0306,\n",
       "                       0.0023, -0.0296,  0.0076,  0.0272, -0.0094, -0.0060, -0.0211, -0.0049,\n",
       "                      -0.0317, -0.0164,  0.0229,  0.0054,  0.0012, -0.0291, -0.0305,  0.0203,\n",
       "                      -0.0298,  0.0295,  0.0244, -0.0187, -0.0188,  0.0087,  0.0254,  0.0335,\n",
       "                       0.0203, -0.0045, -0.0108, -0.0113, -0.0266,  0.0045, -0.0314,  0.0354,\n",
       "                      -0.0336,  0.0343, -0.0290, -0.0057,  0.0084,  0.0284,  0.0003, -0.0315,\n",
       "                      -0.0150, -0.0280,  0.0314, -0.0175, -0.0194, -0.0290, -0.0036, -0.0244,\n",
       "                      -0.0047, -0.0159, -0.0253, -0.0207, -0.0342, -0.0337,  0.0147, -0.0201,\n",
       "                      -0.0110,  0.0100, -0.0263, -0.0268, -0.0085, -0.0343, -0.0261, -0.0013,\n",
       "                      -0.0137, -0.0212,  0.0307,  0.0268, -0.0124, -0.0054, -0.0322,  0.0285,\n",
       "                       0.0070, -0.0340,  0.0166, -0.0345,  0.0329, -0.0176,  0.0051, -0.0015,\n",
       "                       0.0100, -0.0343, -0.0165, -0.0188, -0.0021,  0.0320, -0.0025, -0.0087,\n",
       "                      -0.0018, -0.0322, -0.0285, -0.0294, -0.0177,  0.0285,  0.0093,  0.0175,\n",
       "                      -0.0299,  0.0277, -0.0077, -0.0206, -0.0042, -0.0266, -0.0025, -0.0347,\n",
       "                       0.0102, -0.0247,  0.0021, -0.0041,  0.0282,  0.0191, -0.0262, -0.0334,\n",
       "                       0.0150,  0.0130,  0.0329, -0.0194,  0.0331, -0.0292,  0.0137, -0.0022,\n",
       "                      -0.0295,  0.0165, -0.0086,  0.0033,  0.0310, -0.0201,  0.0261, -0.0178,\n",
       "                       0.0110,  0.0231, -0.0180, -0.0074, -0.0107, -0.0292,  0.0029, -0.0216,\n",
       "                       0.0095,  0.0021, -0.0273, -0.0137,  0.0125,  0.0102,  0.0259, -0.0155,\n",
       "                      -0.0288,  0.0281,  0.0057,  0.0003,  0.0128, -0.0013,  0.0109,  0.0065,\n",
       "                      -0.0119, -0.0270, -0.0310, -0.0099, -0.0039,  0.0347, -0.0151,  0.0249,\n",
       "                       0.0227, -0.0067,  0.0181, -0.0123,  0.0074,  0.0292,  0.0279,  0.0323,\n",
       "                      -0.0106, -0.0033,  0.0042, -0.0042, -0.0028, -0.0339,  0.0079,  0.0210,\n",
       "                      -0.0156, -0.0229,  0.0047,  0.0114, -0.0188,  0.0039,  0.0275, -0.0020,\n",
       "                       0.0066, -0.0336,  0.0110, -0.0280,  0.0342,  0.0089, -0.0176,  0.0238,\n",
       "                      -0.0298, -0.0336, -0.0308,  0.0186, -0.0262, -0.0272,  0.0153,  0.0282,\n",
       "                       0.0078,  0.0246,  0.0185, -0.0107, -0.0134,  0.0008,  0.0183,  0.0159,\n",
       "                      -0.0223,  0.0130,  0.0138, -0.0146,  0.0324, -0.0280,  0.0161,  0.0031,\n",
       "                      -0.0061, -0.0227, -0.0099, -0.0334,  0.0225, -0.0236,  0.0137, -0.0265,\n",
       "                       0.0141,  0.0024,  0.0205, -0.0253,  0.0098,  0.0209,  0.0132,  0.0347,\n",
       "                       0.0063,  0.0308,  0.0124,  0.0117,  0.0279,  0.0196,  0.0011, -0.0244,\n",
       "                       0.0306,  0.0311,  0.0079, -0.0258, -0.0002, -0.0038, -0.0113,  0.0102,\n",
       "                      -0.0100, -0.0312,  0.0190, -0.0259,  0.0155,  0.0158,  0.0255, -0.0239,\n",
       "                       0.0057, -0.0221,  0.0279,  0.0054,  0.0256, -0.0013, -0.0238,  0.0099,\n",
       "                      -0.0286, -0.0320,  0.0325, -0.0032, -0.0108, -0.0039, -0.0090, -0.0157,\n",
       "                       0.0165, -0.0274, -0.0111, -0.0285, -0.0109,  0.0017, -0.0157,  0.0002,\n",
       "                       0.0141,  0.0169, -0.0234,  0.0071, -0.0335,  0.0246,  0.0203,  0.0247,\n",
       "                      -0.0061,  0.0298, -0.0245, -0.0007, -0.0084,  0.0190, -0.0058, -0.0309,\n",
       "                       0.0117, -0.0343,  0.0064, -0.0141,  0.0175, -0.0351,  0.0198, -0.0076,\n",
       "                      -0.0216,  0.0011, -0.0083, -0.0192, -0.0230,  0.0342,  0.0062, -0.0300,\n",
       "                       0.0307, -0.0342, -0.0050,  0.0099,  0.0215,  0.0166,  0.0193,  0.0087,\n",
       "                       0.0129, -0.0091,  0.0345, -0.0336,  0.0253, -0.0140, -0.0144,  0.0271,\n",
       "                       0.0294, -0.0305,  0.0302, -0.0199,  0.0279, -0.0220,  0.0279, -0.0287,\n",
       "                       0.0256, -0.0082, -0.0047,  0.0025,  0.0337, -0.0132,  0.0064, -0.0188,\n",
       "                      -0.0239,  0.0213,  0.0062, -0.0159, -0.0008,  0.0312, -0.0029, -0.0249,\n",
       "                       0.0261, -0.0165, -0.0183, -0.0090,  0.0315, -0.0247,  0.0204,  0.0013,\n",
       "                       0.0192,  0.0005, -0.0080,  0.0181,  0.0051,  0.0180,  0.0220,  0.0250,\n",
       "                      -0.0035, -0.0189, -0.0254,  0.0266, -0.0198,  0.0150,  0.0136,  0.0221,\n",
       "                      -0.0202, -0.0274,  0.0232,  0.0206,  0.0169, -0.0033,  0.0076, -0.0021,\n",
       "                       0.0236, -0.0213,  0.0027,  0.0111,  0.0256,  0.0202, -0.0184, -0.0214,\n",
       "                      -0.0119,  0.0267,  0.0288, -0.0181,  0.0188,  0.0107, -0.0251,  0.0311,\n",
       "                       0.0062,  0.0177,  0.0106,  0.0049,  0.0348,  0.0232, -0.0104, -0.0213,\n",
       "                      -0.0188, -0.0139, -0.0116, -0.0250,  0.0232,  0.0213, -0.0154, -0.0121,\n",
       "                      -0.0009, -0.0135, -0.0305, -0.0297,  0.0044,  0.0045, -0.0150, -0.0276,\n",
       "                       0.0209,  0.0241, -0.0058, -0.0284,  0.0236,  0.0125,  0.0343,  0.0253,\n",
       "                       0.0278, -0.0056, -0.0155,  0.0360, -0.0243,  0.0356, -0.0117,  0.0200,\n",
       "                       0.0316, -0.0038,  0.0341, -0.0180,  0.0319,  0.0205,  0.0204,  0.0293,\n",
       "                       0.0201, -0.0238,  0.0090, -0.0105])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0308, -0.0174, -0.0031,  ..., -0.0192, -0.0250,  0.0345],\n",
       "                      [ 0.0385,  0.0244, -0.0239,  ...,  0.0034, -0.0303,  0.0019],\n",
       "                      [-0.0096,  0.0147,  0.0440,  ...,  0.0321,  0.0112, -0.0221],\n",
       "                      ...,\n",
       "                      [ 0.0328,  0.0249,  0.0264,  ...,  0.0219,  0.0367, -0.0133],\n",
       "                      [ 0.0046,  0.0134, -0.0327,  ...,  0.0368,  0.0061, -0.0247],\n",
       "                      [ 0.0090, -0.0062, -0.0145,  ..., -0.0053, -0.0247, -0.0459]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0660,  0.0250, -0.0467,  0.0050, -0.0057, -0.0053, -0.0144, -0.0343,\n",
       "                      -0.0445, -0.0088]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save, Load and Resuming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch' : epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss\n",
    "},checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 1.0000000000000004e-08\n",
       "    momentum: 0.5\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0620, requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.train of Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
